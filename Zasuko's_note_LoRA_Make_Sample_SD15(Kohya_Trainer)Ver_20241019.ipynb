{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmCPmqFL6hCQ"
      },
      "source": [
        "# 🍀オリジナルLoRA の作成_🌱お試しサンプル版（SD1.5版）\n",
        "### ※Lora Trainer by Zasuko Michikusa\n",
        "🌱This is based on the work of [Kohya-ss](https://github.com/kohya-ss/sd-scripts) and [Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb).and [Hollowstrawberry](https://github.com/hollowstrawberry/kohya-colab) Thank you!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXg7j5p-DW4p",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title # 🌎＜Step1＞ Google Driveと接続\n",
        "\n",
        "#@markdown # 🥚はじめにやること➊❷\n",
        "#@markdown #＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "#@markdown #➊🐣マイドライブに階層フォルダを構成\n",
        "#@markdown ### 　・予め下記🍀マークのフォルダと必要ファイルを用意しましょう！\n",
        "#@markdown ###～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～\n",
        "#@markdown ###＜🌎GoogleDrive＞\n",
        "#@markdown ###📁マイドライブ\n",
        "#@markdown ###└📁checkpoint　　　← 🍀ベースに使用するCheckpointモデルを格納\n",
        "#@markdown ###└📁train_img　　　 ← 🍀学習用の画像とキャプションを格納\n",
        "#@markdown ###└📁Loras 　　　　　←(※1)　作成するLoRAプロジェクト単位でフォルダ管理します\n",
        "#@markdown ###＿└📁project_name　←(※2)　❷で入力した名前になる（完成したLoRAファイルの名前にもなる）\n",
        "#@markdown ###＿＿└📁output　　　← (※3)　完成した LoRAファイル が格納される\n",
        "#@markdown ###＿＿└📁dataset　  　 ← (※4)　学習に使う画像とキャプションを入れるフォルダ\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import re\n",
        "import toml\n",
        "from time import time\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# これらは過去の実行からの情報を保持します\n",
        "if \"model_url\" in globals():\n",
        "    old_model_url = model_url\n",
        "else:\n",
        "    old_model_url = None\n",
        "if \"dependencies_installed\" not in globals():\n",
        "    dependencies_installed = False\n",
        "if \"model_file\" not in globals():\n",
        "    model_file = None\n",
        "\n",
        "# 他のセルによって設定される可能性のある変数。これらはレガシーな変数です。\n",
        "if \"custom_dataset\" not in globals():\n",
        "    custom_dataset = None\n",
        "if \"override_dataset_config_file\" not in globals():\n",
        "    override_dataset_config_file = None\n",
        "if \"override_config_file\" not in globals():\n",
        "    override_config_file = None\n",
        "if \"optimizer\" not in globals():\n",
        "    optimizer = \"AdamW8bit\"\n",
        "if \"optimizer_args\" not in globals():\n",
        "    optimizer_args = None\n",
        "if \"continue_from_lora\" not in globals():\n",
        "    continue_from_lora = \"\"\n",
        "if \"weighted_captions\" not in globals():\n",
        "    weighted_captions = False\n",
        "if \"adjust_tags\" not in globals():\n",
        "    adjust_tags = False\n",
        "if \"keep_tokens_weight\" not in globals():\n",
        "    keep_tokens_weight = 1.0\n",
        "\n",
        "COLAB = True  # 低RAMモードのための設定\n",
        "XFORMERS = True\n",
        "SOURCE = \"https://github.com/uYouUs/sd-scripts\"\n",
        "COMMIT = None\n",
        "BETTER_EPOCH_NAMES = True\n",
        "LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "#@markdown ###～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～\n",
        "#@markdown #【詳しい説明】\n",
        "#@markdown ####💡「📁Loras」以下は🌎＜Step1＞の処理後に自動生成されます\n",
        "#@markdown ##### ※1 名前を付けたプロジェクト単位で自動的にフォルダ管理します\n",
        "#@markdown ##### ※2「project_name」フォルダ名を付けて下記フォルダを格納\n",
        "#@markdown ##### ※3「output」フォルダだけ作成しておく\n",
        "#@markdown ##### ※4「dateset」に学習用画像とキャプションファイルを格納\n",
        "#@markdown ##### ・学習用画像の画像枚数は「20枚～50枚」（解像度：512×512）\n",
        "#@markdown ##### ・キャプションファイルは、予め「dataset-tag-editor」で作成してください。\n",
        "\n",
        "#@markdown #ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "\n",
        "#@markdown #❷🐔作成する「LoRA名」の設定\n",
        "#@markdown ### 　・自作する「LoLA名」を入力してください。（「.」スペース等は使用不可）\n",
        "project_name = \"ここに任意のLoRAの名前を入力\"  # @param {type:\"string\"}\n",
        "project_name = project_name.strip()\n",
        "\n",
        "folder_structure = \"カテゴリごとに整理 (MyDrive/Loras/project_name/dataset)\"  # @param [\"カテゴリごとに整理 (MyDrive/Loras/project_name/dataset)\"]\n",
        "#@markdown #＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "\n",
        "#@markdown ※Stable Diffusion 2系モデルを使用する場合はチェックを入れてください。\n",
        "custom_model_is_based_on_sd2 = False  # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "def create_folders():\n",
        "    # Google Driveがマウントされていない場合はマウント\n",
        "    if COLAB and not os.path.exists('/content/drive'):\n",
        "        from google.colab import drive\n",
        "        print(\"📂 Google Driveに接続中...\")\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "    # 作成したいフォルダのパスをリストで指定\n",
        "    folders_to_create = [\n",
        "        f'/content/drive/MyDrive/Loras/{project_name}',  # プロジェクトフォルダ\n",
        "        f'/content/drive/MyDrive/Loras/{project_name}/dataset',  # データセットフォルダ\n",
        "        f'/content/drive/MyDrive/Loras/{project_name}/output',  # 出力フォルダ\n",
        "        f'/content/drive/MyDrive/Loras/{project_name}/config'  # コンフィグフォルダ\n",
        "    ]\n",
        "\n",
        "    # フォルダを作成する\n",
        "    for folder in folders_to_create:\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "        print(f\"📂 フォルダ {folder} が作成されました\")\n",
        "\n",
        "# 関数を実行\n",
        "create_folders()\n",
        "\n",
        "print(\"🌎GoogleDriveとの接続が完了しました！ 🌱Step➋へ進んでください\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OglZzI_ujZq-",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title # 🌱＜Step2＞ 学習をはじめる前の設定\n",
        "\n",
        "#@markdown # 📔学習に関する設定➊❷③\n",
        "#@markdown #＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "#@markdown #➊「📚学習用の画像」＆「📑キャプション」の格納\n",
        "#@markdown ### 　・「📂dataset」内に「学習用の画像」と「キャプション」をアップロードしてください。\n",
        "#@markdown ### 　※◀のフォルダリストリストを開いて、対象の「📂dataset」を右クリック\n",
        "\n",
        "#@markdown #ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "\n",
        "#@markdown #❷ 🔀学習に使用するモデルの指定\n",
        "#@markdown ### 　・GoogleDrive内にある、ベースモデル（Checkpoint）のパスを指定してください。\n",
        "checkpoint_model_path = \"/content/drive/MyDrive/Original_Lora/checkpoint/～～～～～～～～～～～～\"  # @param {type:\"string\"}\n",
        "\n",
        "# モデルパスの判定\n",
        "model_url = checkpoint_model_path  # Google Drive上のパスを指定\n",
        "\n",
        "# モデルファイルが存在するかチェック\n",
        "if not os.path.exists(model_url):\n",
        "    raise FileNotFoundError(f\"モデルファイルが見つかりません: {model_url}\")\n",
        "\n",
        "# モデルをロードする処理\n",
        "model_file = model_url  # そのままモデルファイルのパスを利用\n",
        "\n",
        "# パスやファイルが正しいかどうかを確認するための簡単な出力\n",
        "print(f\"使用するモデルのパス: {model_url}\")\n",
        "\n",
        "#@markdown #ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "\n",
        "#@markdown #③ ⚙️各種パラメータ設定（設定省略）\n",
        "#@markdown ### 　♻️ 🌱お試し版なので各種、私のオススメ固定値で設定済みです。\n",
        "# 固定された学習設定\n",
        "resolution = 512  # 解像度を512に固定\n",
        "flip_aug = False  # タグのシャッフルをしない\n",
        "shuffle_tags = True  # タグシャッフルはTrueで固定\n",
        "\n",
        "shuffle_caption = shuffle_tags\n",
        "activation_tags = 1  # アクティベーションタグは1に固定\n",
        "keep_tokens = int(activation_tags)\n",
        "\n",
        "# 学習ステップに関する設定\n",
        "num_repeats = 10  # 繰り返し回数は10に固定\n",
        "max_train_epochs = 10  # エポック数を10に固定\n",
        "max_train_steps = None  # ステップ数は使用しない\n",
        "\n",
        "save_every_n_epochs = 10  # 10エポックごとに保存\n",
        "keep_only_last_n_epochs = 10  # 最新の10エポックのみ保持\n",
        "\n",
        "train_batch_size = 2  # バッチサイズを2に固定\n",
        "\n",
        "# 学習率とスケジューラの設定\n",
        "unet_lr = 5e-4  # UNetの学習率を5e-4に固定\n",
        "text_encoder_lr = 1e-4  # テキストエンコーダの学習率を1e-4に固定\n",
        "\n",
        "lr_scheduler = \"cosine_with_restarts\"  # スケジューラは`cosine_with_restarts`に固定\n",
        "lr_scheduler_num_cycles = 3  # サイクル数を3に固定\n",
        "lr_scheduler_power = 0  # ポリノミアルのパワーを0に固定\n",
        "\n",
        "lr_warmup_ratio = 0.05  # ウォームアップ比率を5%に固定\n",
        "lr_warmup_steps = 0  # ウォームアップステップは使用しない\n",
        "\n",
        "min_snr_gamma = True  # SNRガンマを有効にする\n",
        "min_snr_gamma_value = 5.0  # SNRガンマの値を5.0に固定\n",
        "\n",
        "# LoRAのタイプとネットワーク設定\n",
        "lora_type = \"LoRA\"  # LoRAタイプを\"LoRA\"に固定\n",
        "network_dim = 16  # ネットワークの次元を16に固定\n",
        "network_alpha = 8  # ネットワークのアルファを8に固定\n",
        "\n",
        "# LoConの追加設定\n",
        "conv_dim = 8  # LoConの畳み込み次元を8に固定\n",
        "conv_alpha = 4  # LoConのアルファを4に固定\n",
        "\n",
        "network_module = \"networks.lora\"\n",
        "network_args = None\n",
        "if lora_type.lower() == \"locon\":\n",
        "    network_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\"]\n",
        "\n",
        "#@markdown #＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "#@markdown # 👌 ↑ここまで設定できたら準備完了↑\n",
        "#@markdown 🚩🌱＜Step2＞の（▶️）実行ボタンを押すと、LoRAの学習が開始されます。 <p>\n",
        "\n",
        "\n",
        "\n",
        "# ここから下が学習コマンド\n",
        "\n",
        "if optimizer.lower() == \"prodigy\" or \"dadapt\" in optimizer.lower():\n",
        "  if override_values_for_dadapt_and_prodigy:\n",
        "    unet_lr = 0.5\n",
        "    text_encoder_lr = 0.5\n",
        "    lr_scheduler = \"constant_with_warmup\"\n",
        "    lr_warmup_ratio = 0.05\n",
        "    network_alpha = network_dim\n",
        "\n",
        "  if not optimizer_args:\n",
        "    optimizer_args = [\"decouple=True\",\"weight_decay=0.01\",\"betas=[0.9,0.999]\"]\n",
        "    if optimizer == \"Prodigy\":\n",
        "      optimizer_args.extend([\"d_coef=2\",\"use_bias_correction=True\"])\n",
        "      if lr_warmup_ratio > 0:\n",
        "        optimizer_args.append(\"safeguard_warmup=True\")\n",
        "      else:\n",
        "        optimizer_args.append(\"safeguard_warmup=False\")\n",
        "\n",
        "root_dir = \"/content\" if COLAB else \"~/Loras\"\n",
        "deps_dir = os.path.join(root_dir, \"deps\")\n",
        "repo_dir = os.path.join(root_dir, \"kohya-trainer\")\n",
        "\n",
        "if \"/Loras\" in folder_structure:\n",
        "  main_dir      = os.path.join(root_dir, \"drive/MyDrive/Loras\") if COLAB else root_dir\n",
        "  log_folder    = os.path.join(main_dir, \"_logs\")\n",
        "  config_folder = os.path.join(main_dir, project_name)\n",
        "  images_folder = os.path.join(main_dir, project_name, \"dataset\")\n",
        "  output_folder = os.path.join(main_dir, project_name, \"output\")\n",
        "else:\n",
        "  main_dir      = os.path.join(root_dir, \"drive/MyDrive/lora_training\") if COLAB else root_dir\n",
        "  images_folder = os.path.join(main_dir, \"datasets\", project_name)\n",
        "  output_folder = os.path.join(main_dir, \"output\", project_name)\n",
        "  config_folder = os.path.join(main_dir, \"config\", project_name)\n",
        "  log_folder    = os.path.join(main_dir, \"log\")\n",
        "\n",
        "config_file = os.path.join(config_folder, \"training_config.toml\")\n",
        "dataset_config_file = os.path.join(config_folder, \"dataset_config.toml\")\n",
        "accelerate_config_file = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "def install_dependencies():\n",
        "  os.chdir(root_dir)\n",
        "  !git clone {SOURCE} {repo_dir}\n",
        "  os.chdir(repo_dir)\n",
        "  if COMMIT:\n",
        "    !git reset --hard {COMMIT}\n",
        "  !wget https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/train_network_wrapper.py -q -O train_network_wrapper.py\n",
        "  !wget https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/dracula.py -q -O dracula.py\n",
        "\n",
        "  !apt -y update -qq\n",
        "  !apt -y install aria2 -qq\n",
        "  !pip install accelerate==0.25.0 transformers==4.36.2 diffusers[torch]==0.25.0 ftfy==6.1.1 \\\n",
        "    opencv-python==4.8.1.78 einops==0.7.0 pytorch-lightning==1.9.0 bitsandbytes==0.43.0 \\\n",
        "    prodigyopt==1.0 lion-pytorch==0.0.6 tensorboard safetensors==0.4.2 altair==4.2.2 \\\n",
        "    easygui==0.98.3 toml==0.10.2 voluptuous==0.13.1 huggingface-hub==0.20.1 imagesize==1.4.1 \\\n",
        "    rich==13.7.1 torch==2.4.1+cu121 triton\n",
        "  !pip install -e .\n",
        "  if XFORMERS:\n",
        "    !pip install xformers==0.0.28.post1\n",
        "\n",
        "  # patch kohya for minor stuff\n",
        "  if COLAB:\n",
        "    !sed -i \"s@cpu@cuda@\" library/model_util.py # low ram\n",
        "  if LOAD_TRUNCATED_IMAGES:\n",
        "    !sed -i 's/from PIL import Image/from PIL import Image, ImageFile\\nImageFile.LOAD_TRUNCATED_IMAGES=True/g' library/train_util.py # fix truncated jpegs error\n",
        "  if BETTER_EPOCH_NAMES:\n",
        "    !sed -i 's/{:06d}/{:02d}/g' library/train_util.py # make epoch names shorter\n",
        "    !sed -i 's/\".\" + args.save_model_as)/\"-{:02d}.\".format(num_train_epochs) + args.save_model_as)/g' train_network.py # name of the last epoch will match the rest\n",
        "\n",
        "  from accelerate.utils import write_basic_config\n",
        "  if not os.path.exists(accelerate_config_file):\n",
        "    write_basic_config(save_location=accelerate_config_file)\n",
        "\n",
        "  os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "  os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
        "  os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "\n",
        "def validate_dataset():\n",
        "    global lr_warmup_steps, lr_warmup_ratio, caption_extension, keep_tokens, keep_tokens_weight, weighted_captions, adjust_tags\n",
        "    supported_types = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
        "\n",
        "    print(\"\\n💿 データセットを確認中...\")\n",
        "\n",
        "    # プロジェクト名のチェック\n",
        "    if not project_name.strip() or any(c in project_name for c in \" .()\\\"'\\\\/\"):\n",
        "        print(\"👀 エラー: 有効なプロジェクト名を指定してください。\")\n",
        "        return\n",
        "\n",
        "    # データセットフォルダの存在確認\n",
        "    if not os.path.exists(images_folder):\n",
        "        print(f\"👀 エラー: フォルダ {images_folder} が存在しません。\")\n",
        "        return\n",
        "    else:\n",
        "        print(f\"データセットフォルダ {images_folder} は存在します。\")\n",
        "\n",
        "    if custom_dataset:\n",
        "        try:\n",
        "            datconf = toml.loads(custom_dataset)\n",
        "            datasets = [d for d in datconf[\"datasets\"][0][\"subsets\"]]\n",
        "        except:\n",
        "            print(f\"👀 エラー: カスタムデータセットが無効かエラーを含んでいます！テンプレートを確認してください。\")\n",
        "            return\n",
        "        reg = [d.get(\"image_dir\") for d in datasets if d.get(\"is_reg\", False)]\n",
        "        datasets_dict = {d[\"image_dir\"]: d[\"num_repeats\"] for d in datasets}\n",
        "        folders = datasets_dict.keys()\n",
        "        files = [f for folder in folders for f in os.listdir(folder)]\n",
        "        images_repeats = {folder: (len([f for f in os.listdir(folder) if f.lower().endswith(supported_types)]), datasets_dict[folder]) for folder in folders}\n",
        "    else:\n",
        "        reg = []\n",
        "        folders = [images_folder]\n",
        "        files = os.listdir(images_folder)\n",
        "        images_repeats = {images_folder: (len([f for f in files if f.lower().endswith(supported_types)]), num_repeats)}\n",
        "\n",
        "    for folder in folders:\n",
        "        if not os.path.exists(folder):\n",
        "            print(f\"👀 エラー: フォルダ {folder.replace('/content/drive/', '')} が存在しません。\")\n",
        "            return\n",
        "    for folder, (img, rep) in images_repeats.items():\n",
        "        if not img:\n",
        "            print(f\"👀 エラー: フォルダ {folder.replace('/content/drive/', '')} が空です。\")\n",
        "            return\n",
        "    for f in files:\n",
        "        if not f.lower().endswith((\".txt\", \".npz\")) and not f.lower().endswith(supported_types):\n",
        "            print(f\"👀 エラー: データセット内に無効なファイルがあります: \\\"{f}\\\"。中止します。\")\n",
        "            return\n",
        "\n",
        "    if not [txt for txt in files if txt.lower().endswith(\".txt\")]:\n",
        "        caption_extension = \"\"\n",
        "    if continue_from_lora and not (continue_from_lora.endswith(\".safetensors\") and os.path.exists(continue_from_lora)):\n",
        "        print(f\"👀 エラー: 既存のLoraへの無効なパス。例: /content/drive/MyDrive/Loras/example.safetensors\")\n",
        "        return\n",
        "\n",
        "    pre_steps_per_epoch = sum(img * rep for (img, rep) in images_repeats.values())\n",
        "    steps_per_epoch = pre_steps_per_epoch / train_batch_size\n",
        "    total_steps = max_train_steps or int(max_train_epochs * steps_per_epoch)\n",
        "    estimated_epochs = int(total_steps / steps_per_epoch)\n",
        "    lr_warmup_steps = int(total_steps * lr_warmup_ratio)\n",
        "\n",
        "    for folder, (img, rep) in images_repeats.items():\n",
        "        print(\"📁\" + folder.replace(\"/content/drive/\", \"\") + (\" (正規化)\" if folder in reg else \"\"))\n",
        "        print(f\"📈 {img}枚の画像が見つかり、{rep}回の繰り返しで、合計 {img * rep} ステップです。\")\n",
        "    print(f\"📉 {pre_steps_per_epoch} ステップを {train_batch_size} バッチサイズで割り、1エポックあたり {steps_per_epoch} ステップです。\")\n",
        "    if max_train_epochs:\n",
        "        print(f\"🌀 合計で {total_steps} ステップの学習を {max_train_epochs} エポック行います。\")\n",
        "    else:\n",
        "        print(f\"🌀 合計で {total_steps} ステップを {estimated_epochs} エポックで分割して学習します。\")\n",
        "\n",
        "    if total_steps > 10000:\n",
        "        print(\"👀 エラー: ステップが多すぎます。何か間違いがあるかもしれません。中止します...\")\n",
        "        return\n",
        "\n",
        "    if adjust_tags:\n",
        "        print(f\"\\n📎 重み付きタグ: {'ON' if weighted_captions else 'OFF'}\")\n",
        "        if weighted_captions:\n",
        "            print(f\"📎 {keep_tokens} アクティベーションタグに {keep_tokens_weight} の重みを適用します。\")\n",
        "        print(\"📎 タグを調整中...\")\n",
        "        adjust_weighted_tags(folders, keep_tokens, keep_tokens_weight, weighted_captions)\n",
        "\n",
        "    return True\n",
        "\n",
        "def adjust_weighted_tags(folders, keep_tokens: int, keep_tokens_weight: float, weighted_captions: bool):\n",
        "  weighted_tag = re.compile(r\"\\((.+?):[.\\d]+\\)(,|$)\")\n",
        "  for folder in folders:\n",
        "    for txt in [f for f in os.listdir(folder) if f.lower().endswith(\".txt\")]:\n",
        "      with open(os.path.join(folder, txt), 'r') as f:\n",
        "        content = f.read()\n",
        "      # reset previous changes\n",
        "      content = content.replace('\\\\', '')\n",
        "      content = weighted_tag.sub(r'\\1\\2', content)\n",
        "      if weighted_captions:\n",
        "        # re-apply changes\n",
        "        content = content.replace(r'(', r'\\(').replace(r')', r'\\)').replace(r':', r'\\:')\n",
        "        if keep_tokens_weight > 1:\n",
        "          tags = [s.strip() for s in content.split(\",\")]\n",
        "          for i in range(min(keep_tokens, len(tags))):\n",
        "            tags[i] = f'({tags[i]}:{keep_tokens_weight})'\n",
        "          content = \", \".join(tags)\n",
        "      with open(os.path.join(folder, txt), 'w') as f:\n",
        "        f.write(content)\n",
        "\n",
        "def create_config():\n",
        "    global dataset_config_file, config_file, model_file\n",
        "\n",
        "    # 画像フォルダ内のファイル一覧を取得\n",
        "    files = os.listdir(images_folder)  # ここでimages_folder内のファイルを取得\n",
        "\n",
        "    # caption_extensionの定義\n",
        "    if not [txt for txt in files if txt.lower().endswith(\".txt\")]:\n",
        "        caption_extension = \"\"\n",
        "    else:\n",
        "        caption_extension = \".txt\"\n",
        "\n",
        "    if override_config_file:\n",
        "        config_file = override_config_file\n",
        "        print(f\"\\n🙆 Using custom config file {config_file}\")\n",
        "    else:\n",
        "        config_dict = {\n",
        "            \"additional_network_arguments\": {\n",
        "                \"unet_lr\": unet_lr,\n",
        "                \"text_encoder_lr\": text_encoder_lr,\n",
        "                \"network_dim\": network_dim,\n",
        "                \"network_alpha\": network_alpha,\n",
        "                \"network_module\": network_module,\n",
        "                \"network_args\": network_args,\n",
        "                \"network_train_unet_only\": True if text_encoder_lr == 0 else None,\n",
        "                \"network_weights\": continue_from_lora if continue_from_lora else None\n",
        "            },\n",
        "            \"optimizer_arguments\": {\n",
        "                \"learning_rate\": unet_lr,\n",
        "                \"lr_scheduler\": lr_scheduler,\n",
        "                \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "                \"lr_scheduler_power\": lr_scheduler_power if lr_scheduler == \"polynomial\" else None,\n",
        "                \"lr_warmup_steps\": lr_warmup_steps if lr_scheduler != \"constant\" else None,\n",
        "                \"optimizer_type\": optimizer,\n",
        "                \"optimizer_args\": optimizer_args if optimizer_args else None,\n",
        "            },\n",
        "            \"training_arguments\": {\n",
        "                \"max_train_steps\": max_train_steps,\n",
        "                \"max_train_epochs\": max_train_epochs,\n",
        "                \"save_every_n_epochs\": save_every_n_epochs,\n",
        "                \"save_last_n_epochs\": keep_only_last_n_epochs,\n",
        "                \"train_batch_size\": train_batch_size,\n",
        "                \"noise_offset\": None,\n",
        "                \"clip_skip\": 2,\n",
        "                \"min_snr_gamma\": min_snr_gamma_value,\n",
        "                \"weighted_captions\": weighted_captions,\n",
        "                \"seed\": 42,\n",
        "                \"max_token_length\": 225,\n",
        "                \"xformers\": XFORMERS,\n",
        "                \"lowram\": COLAB,\n",
        "                \"max_data_loader_n_workers\": 8,\n",
        "                \"persistent_data_loader_workers\": True,\n",
        "                \"save_precision\": \"fp16\",\n",
        "                \"mixed_precision\": \"fp16\",\n",
        "                \"output_dir\": output_folder,\n",
        "                \"logging_dir\": log_folder,\n",
        "                \"output_name\": project_name,\n",
        "                \"log_prefix\": project_name,\n",
        "            },\n",
        "            \"model_arguments\": {\n",
        "                \"pretrained_model_name_or_path\": model_file,\n",
        "                \"v2\": custom_model_is_based_on_sd2,\n",
        "                \"v_parameterization\": True if custom_model_is_based_on_sd2 else None,\n",
        "            },\n",
        "            \"saving_arguments\": {\n",
        "                \"save_model_as\": \"safetensors\",\n",
        "            },\n",
        "            \"dreambooth_arguments\": {\n",
        "                \"prior_loss_weight\": 1.0,\n",
        "            },\n",
        "            \"dataset_arguments\": {\n",
        "                \"cache_latents\": True,\n",
        "                \"caption_extension\": caption_extension,  # ここで追加\n",
        "            },\n",
        "        }\n",
        "\n",
        "        for key in config_dict:\n",
        "            if isinstance(config_dict[key], dict):\n",
        "                config_dict[key] = {k: v for k, v in config_dict[key].items() if v is not None}\n",
        "\n",
        "        with open(config_file, \"w\") as f:\n",
        "            f.write(toml.dumps(config_dict))\n",
        "        print(f\"\\n📄 Config saved to {config_file}\")\n",
        "\n",
        "    if override_dataset_config_file:\n",
        "        dataset_config_file = override_dataset_config_file\n",
        "        print(f\"🙆 Using custom dataset config file {dataset_config_file}\")\n",
        "    else:\n",
        "        dataset_config_dict = {\n",
        "            \"general\": {\n",
        "                \"resolution\": resolution,\n",
        "                \"shuffle_caption\": shuffle_caption,\n",
        "                \"keep_tokens\": keep_tokens,\n",
        "                \"flip_aug\": flip_aug,\n",
        "                \"caption_extension\": caption_extension,\n",
        "                \"enable_bucket\": True,\n",
        "                \"bucket_reso_steps\": 64,\n",
        "                \"bucket_no_upscale\": False,\n",
        "                \"min_bucket_reso\": 320 if resolution > 640 else 256,\n",
        "                \"max_bucket_reso\": 1280 if resolution > 640 else 1024,\n",
        "            },\n",
        "            \"datasets\": toml.loads(custom_dataset)[\"datasets\"] if custom_dataset else [\n",
        "                {\n",
        "                    \"subsets\": [\n",
        "                        {\n",
        "                            \"num_repeats\": num_repeats,\n",
        "                            \"image_dir\": images_folder,\n",
        "                            \"class_tokens\": None if caption_extension else project_name\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        for key in dataset_config_dict:\n",
        "            if isinstance(dataset_config_dict[key], dict):\n",
        "                dataset_config_dict[key] = {k: v for k, v in dataset_config_dict[key].items() if v is not None}\n",
        "\n",
        "        with open(dataset_config_file, \"w\") as f:\n",
        "            f.write(toml.dumps(dataset_config_dict))\n",
        "        print(f\"📄 Dataset config saved to {dataset_config_file}\")\n",
        "\n",
        "\n",
        "\n",
        "def download_model():\n",
        "    global old_model_url, model_url, model_file\n",
        "    real_model_url = model_url.strip()\n",
        "\n",
        "    # Google Driveのファイルパスをそのまま使用する場合\n",
        "    if real_model_url.startswith(\"/content/drive/\"):\n",
        "        print(f\"🔀 Using model directly from Google Drive: {real_model_url}\")\n",
        "        model_file = real_model_url\n",
        "        return True\n",
        "    else:\n",
        "        # 通常のHTTP/HTTPSダウンロード処理\n",
        "        model_file = \"/content/downloaded_model.safetensors\"\n",
        "        if os.path.exists(model_file):\n",
        "            os.remove(model_file)\n",
        "\n",
        "        if m := re.search(r\"(?:https?://)?(?:www\\.)?huggingface\\.co/[^/]+/[^/]+/blob\", model_url):\n",
        "            real_model_url = real_model_url.replace(\"blob\", \"resolve\")\n",
        "        elif m := re.search(r\"(?:https?://)?(?:www\\\\.)?civitai\\.com/models/([0-9]+)(/[A-Za-z0-9-_]+)?\", model_url):\n",
        "            if m.group(2):\n",
        "                model_file = f\"/content{m.group(2)}.safetensors\"\n",
        "            if m := re.search(r\"modelVersionId=([0-9]+)\", model_url):\n",
        "                real_model_url = f\"https://civitai.com/api/download/models/{m.group(1)}\"\n",
        "            else:\n",
        "                raise ValueError(\"Invalid civitai link or missing modelVersionId.\")\n",
        "\n",
        "        # ダウンロード処理\n",
        "        !aria2c \"{real_model_url}\" --console-log-level=warn -c -s 16 -x 16 -k 10M -d / -o \"{model_file}\"\n",
        "\n",
        "    # safetensors形式かどうかを確認\n",
        "    if model_file.lower().endswith(\".safetensors\"):\n",
        "        from safetensors.torch import load_file as load_safetensors\n",
        "        try:\n",
        "            test = load_safetensors(model_file)\n",
        "            del test\n",
        "        except:\n",
        "            new_model_file = os.path.splitext(model_file)[0]+\".ckpt\"\n",
        "            shutil.move(model_file, new_model_file)\n",
        "            model_file = new_model_file\n",
        "            print(f\"Renamed model to {os.path.splitext(model_file)[0]}.ckpt\")\n",
        "\n",
        "    # .ckpt形式の場合\n",
        "    if model_file.lower().endswith(\".ckpt\"):\n",
        "        from torch import load as load_ckpt\n",
        "        try:\n",
        "            test = load_ckpt(model_file)\n",
        "            del test\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def main():\n",
        "  global dependencies_installed\n",
        "\n",
        "  if COLAB and not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    print(\"📂 Connecting to Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "  for dir in (main_dir, deps_dir, repo_dir, log_folder, images_folder, output_folder, config_folder):\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "  if not validate_dataset():\n",
        "    return\n",
        "\n",
        "  if not dependencies_installed:\n",
        "    print(\"\\n🏠 Installing dependencies...\\n\")\n",
        "    t0 = time()\n",
        "    install_dependencies()\n",
        "    t1 = time()\n",
        "    dependencies_installed = True\n",
        "    print(f\"\\n✅ Installation finished in {int(t1-t0)} seconds.\")\n",
        "  else:\n",
        "    print(\"\\n✅ Dependencies already installed.\")\n",
        "\n",
        "  if old_model_url != model_url or not model_file or not os.path.exists(model_file):\n",
        "    print(\"\\n🔀 Downloading model...\")\n",
        "    if not download_model():\n",
        "      print(\"\\n👀 Error: The model you selected is invalid or corrupted, or couldn't be downloaded. You can use a civitai or huggingface link, or any direct download link.\")\n",
        "      return\n",
        "    print()\n",
        "  else:\n",
        "    print(\"\\n🔀 Model already downloaded.\\n\")\n",
        "\n",
        "  create_config()\n",
        "\n",
        "  print(\"\\n🚩 Starting trainer...\\n\")\n",
        "  os.chdir(repo_dir)\n",
        "\n",
        "  !accelerate launch --config_file={accelerate_config_file} --num_cpu_threads_per_process=1 train_network_wrapper.py --dataset_config={dataset_config_file} --config_file={config_file}\n",
        "\n",
        "main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}